---
name: "research-guidance"
description: "规划正大杯RPA金融领域调研项目的数据分析任务顺序和方法选择。当需要了解分析流程、选择分析方法、规划研究步骤时调用此skill。"
---

# 调研指导 Skill

## 项目概述

**项目名称**: 金融经济领域RPA技术应用调研  
**研究目标**: 探究RPA技术在金融领域的应用现状、影响因素及发展路径  
**数据来源**: 500份模拟问卷响应 + 原始业务需求数据 + 时间序列数据

---

## 研究框架

```
┌─────────────────────────────────────────────────────────────┐
│                    研究框架总览                              │
├─────────────────────────────────────────────────────────────┤
│  输入层: 问卷数据 + 原始数据 + 时间序列                       │
│  分析层: 描述统计 + SEM + 时间序列 + 文本分析 + 多方法融合    │
│  输出层: 研究结论 + 政策建议 + 发展路径                       │
└─────────────────────────────────────────────────────────────┘
```

---

## 任务执行顺序

### 阶段一: 数据准备与描述性分析 (Day 1-2)

#### 任务1.1: 数据清洗与预处理
**输入**: survey_data_simulated.csv  
**输出**: 清洗后的数据集

```python
# 关键步骤
1. 缺失值检测与处理 (按问卷跳转逻辑)
2. 异常值识别与处理
3. 变量重编码与标签化
4. 数据质量报告生成
```

#### 任务1.2: 样本特征描述
**输入**: 清洗后数据  
**输出**: 描述性统计报告

```python
# 分析内容
- 行业分布 (Q1_industry)
- 企业规模分布 (Q2_employee_scale)
- 数字化阶段分布 (Q2_digital_stage)
- RPA使用年限分布 (Q2_rpa_years)
- 生态角色分布 (Q3_eco_role)
```

#### 任务1.3: 核心变量描述性统计
**输入**: Q9-Q13量表数据  
**输出**: 量表描述性统计表

```python
# 分析内容
- TTF (任务-技术匹配): Q9_TTF1-4
- SI (社会影响): Q10_SI1-4
- PV (感知价值): Q11_PV1-4
- RD (风险感知): Q12_RD1-8
- RV (收益感知): Q13_RV1-6
```

---

### 阶段二: 信效度检验 (Day 2-3)

#### 任务2.1: 信度分析
**方法**: Cronbach's Alpha系数

```python
# 分析量表
- TTF量表信度
- SI量表信度
- PV量表信度
- RD量表信度
- RV量表信度

# 判断标准
- α > 0.8: 优秀
- 0.7 < α < 0.8: 良好
- 0.6 < α < 0.7: 可接受
```

#### 任务2.2: 效度分析
**方法**: 探索性因子分析 (EFA) + 验证性因子分析 (CFA)

```python
# EFA步骤
1. KMO检验 (KMO > 0.7)
2. Bartlett球形检验 (p < 0.05)
3. 因子提取 (主成分分析)
4. 因子旋转 (最大方差法)
5. 因子载荷检验 (载荷 > 0.5)

# CFA步骤
1. 模型构建
2. 拟合指标评估 (CFI > 0.9, RMSEA < 0.08)
3. 聚合效度 (AVE > 0.5)
4. 组合信度 (CR > 0.7)
```

---

### 阶段三: 结构方程模型分析 (Day 3-5)

#### 任务3.1: 模型构建
**理论基础**: TTF模型 + UTAUT模型

```
研究假设:
H1: TTF对感知价值(PV)有正向影响
H2: 社会影响(SI)对感知价值(PV)有正向影响
H3: 感知价值(PV)对使用意愿有正向影响
H4: 风险感知(RD)对使用意愿有负向影响
H5: SI在TTF与PV之间起调节作用
```

#### 任务3.2: 模型估计与检验
**工具**: Python (semopy) 或 R (lavaan)

```python
# SEM分析步骤
1. 测量模型检验
2. 结构模型估计
3. 路径系数检验
4. 模型拟合评估
5. 假设检验结果

# 拟合指标标准
- χ²/df < 3
- CFI > 0.9
- TLI > 0.9
- RMSEA < 0.08
- SRMR < 0.08
```

#### 任务3.3: 多群组分析
**分组变量**: 行业类型、企业规模、数字化阶段

```python
# 分析内容
- 不同行业SEM路径差异
- 不同规模企业影响因素差异
- 不同数字化阶段TTF差异
```

---

### 阶段四: 时间序列分析 (Day 5-6)

#### 任务4.1: 技术发展时间线分析
**输入**: tech_timeline.csv  
**输出**: 技术演进图谱

```python
# 分析内容
1. 技术发展阶段划分
   - 萌芽期 (1929-1999)
   - 发展初期 (2000-2014)
   - 快速发展期 (2015-2019)
   - 智能融合期 (2020-2024)
   - 超自动化期 (2025+)

2. 技术热点演变
   - 关键技术突破节点
   - 企业成立时间分布
   - 技术融合趋势

3. 技术成熟度曲线
   - Gartner技术成熟度模型
   - 技术生命周期分析
```

#### 任务4.2: 政策发展时间线分析
**输入**: policy_timeline.csv  
**输出**: 政策演进图谱

```python
# 分析内容
1. 政策发展阶段
   - 政策萌芽期 (2015-2017)
   - 政策发展期 (2018-2021)
   - 政策深化期 (2022-2024)
   - 政策成熟期 (2025+)

2. 政策类型分析
   - 国家战略政策
   - 国际法规影响
   - 行业监管政策

3. 政策-技术协同分析
   - 政策对技术发展的推动作用
   - 技术发展对政策的影响
```

#### 任务4.3: 技术与政策协同效应
**方法**: 事件研究法 + 格兰杰因果检验

```python
# 分析内容
1. 政策发布对技术发展的短期/长期影响
2. 技术突破对政策制定的引导作用
3. 关键事件的影响程度评估
```

---

### 阶段五: 文本分析 (Day 6-7)

#### 任务5.1: 开放题预处理
**输入**: Q19_pain_points, Q20_suggestions  
**输出**: 清洗后的文本数据

```python
# 预处理步骤
1. 文本清洗 (去除特殊字符、停用词)
2. 分词处理 (jieba分词)
3. 词性标注
4. 实体识别
```

#### 任务5.2: 主题建模
**方法**: BERTopic + LDA

```python
# BERTopic分析
1. 使用预训练BERT模型生成嵌入
2. UMAP降维
3. HDBSCAN聚类
4. 主题提取与命名

# LDA分析 (对比验证)
1. 构建文档-词矩阵
2. 确定最优主题数 (困惑度/一致性)
3. 主题解释与命名
```

#### 任务5.3: 情感分析
**方法**: 基于词典 + 机器学习

```python
# 分析内容
1. 痛点文本情感极性
2. 建议文本情感倾向
3. 不同行业情感差异
```

#### 任务5.4: 关键词提取与共现分析
**方法**: TF-IDF + TextRank + 共现网络

```python
# 分析内容
1. 高频关键词提取
2. 关键词共现网络构建
3. 核心议题识别
```

---

### 阶段六: 多方法融合分析 (Day 7-9)

#### 任务6.1: DEMATEL-ISM分析
**目的**: 识别影响因素及其层级关系

```python
# 分析步骤
1. 构建直接影响矩阵
2. 计算综合影响矩阵
3. 确定原因因素与结果因素
4. 构建层级结构模型
5. 绘制影响因素层级图

# 输入因素
- TTF各维度
- SI各维度
- PV各维度
- RD各维度
- 行业特征变量
```

#### 任务6.2: 模糊AHP-TOPSIS分析
**目的**: 技术成熟度评估与排序

```python
# 分析步骤
1. 构建评价指标体系
2. 模糊AHP确定权重
3. TOPSIS进行技术排序
4. 敏感性分析

# 输入数据
- Q14技术成熟度评估 (三角模糊数)
- 专家权重数据
```

#### 任务6.3: 贝叶斯网络分析
**目的**: 风险传导路径分析

```python
# 分析步骤
1. 构建贝叶斯网络结构
2. 参数学习
3. 概率推理
4. 敏感性分析

# 分析内容
- 风险因素之间的依赖关系
- 关键风险节点识别
- 风险传导路径可视化
```

---

### 阶段七: 综合分析与报告撰写 (Day 9-10)

#### 任务7.1: 结果整合
**输入**: 各阶段分析结果  
**输出**: 综合分析报告

```python
# 整合内容
1. 描述性统计结果
2. SEM模型结果
3. 时间序列分析结果
4. 文本分析结果
5. 多方法融合结果
```

#### 任务7.2: 研究结论提炼
**输出**: 核心研究发现

```python
# 结论框架
1. RPA应用现状总结
2. 影响因素分析结论
3. 技术发展趋势判断
4. 政策建议
5. 研究局限与展望
```

#### 任务7.3: 可视化呈现
**输出**: 图表与可视化

```python
# 可视化内容
1. 样本特征分布图
2. SEM路径图
3. 技术发展时间线图
4. 政策演进图谱
5. 主题词云图
6. 影响因素层级图
```

---

## 方法选择指南

### 根据研究问题选择方法

| 研究问题 | 推荐方法 | 备选方法 |
|----------|----------|----------|
| 影响因素分析 | SEM | 回归分析、DEMATEL |
| 技术评估 | 模糊AHP-TOPSIS | DEA、熵权法 |
| 风险分析 | 贝叶斯网络 | 风险矩阵、蒙特卡洛 |
| 文本挖掘 | BERTopic | LDA、NMF |
| 时间趋势 | 事件研究法 | ARIMA、趋势分析 |
| 因素关系 | DEMATEL-ISM | ISM、解释结构模型 |

### 根据数据类型选择方法

| 数据类型 | 推荐方法 |
|----------|----------|
| 量表数据 | SEM、CFA、EFA |
| 分类数据 | 卡方检验、Logistic回归 |
| 文本数据 | BERTopic、情感分析、TF-IDF |
| 时间序列 | 事件研究、趋势分析 |
| 模糊评价 | 模糊AHP、模糊TOPSIS |

---

## 技术栈推荐

### Python核心库
```python
# 数据处理
pandas, numpy, scipy

# 统计分析
statsmodels, pingouin

# SEM分析
semopy, factor_analyzer

# 文本分析
transformers, bertopic, jieba, snownlp

# 可视化
matplotlib, seaborn, plotly, pyecharts

# 机器学习
scikit-learn, xgboost

# 贝叶斯分析
pgmpy, pymc3
```

### R语言补充
```r
# SEM分析
lavaan, semPlot

# 多方法分析
MCDM, FuzzyAHP
```

---

## 质量控制要点

### 数据质量
- [ ] 缺失值处理合理
- [ ] 异常值识别准确
- [ ] 编码转换正确

### 分析质量
- [ ] 信效度检验通过
- [ ] 模型拟合指标达标
- [ ] 结果可解释性强

### 报告质量
- [ ] 图表规范美观
- [ ] 结论有数据支撑
- [ ] 建议具有可操作性

---

## 交付物清单

1. **数据文件**
   - 清洗后数据集
   - 编码对照表

2. **分析代码**
   - 各阶段分析脚本
   - 可复现的分析流程

3. **分析报告**
   - 描述性统计报告
   - SEM分析报告
   - 时间序列分析报告
   - 文本分析报告
   - 综合分析报告

4. **可视化图表**
   - 核心图表集
   - 交互式可视化

5. **研究论文**
   - 完整研究报告
   - 摘要与PPT
